{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#sparse3d","title":"<code>sparse3d</code>","text":"<p>This package contains implementations of a class for working with data that looks like a single large sparse image containing small regions of dense data. This is designed for working with astronomical images where we often have many small dense images (e.g. stars) set into a sparse frame (e.g. a large astronomical image).</p>"},{"location":"#what-is-sparse3d","title":"What is <code>sparse3D</code>?","text":"<p>We often have large images in astronomy that might look like the sketch below. In this sketch we have a large, sparse image with 4 dense regions; A, B, C, and D. In astronomy we have this situation often, where we have small images of point-like stars spread over large images.</p> <pre><code>+-------------------------------------+\n|                                     |\n|   +-----+        +-----+            |\n|   |     |        |     |            |\n|   |  A  |        |  B  |            |\n|   |     |        |     |            |\n|   +-----+        +-----+            |\n|                                     |\n|                  +-----+            |\n|                  |     |            |\n|   +-----+        |  C  |            |\n|   |     |        |     |            |\n|   |  D  |        +-----+            |\n|   |     |                           |\n|   +-----+                      *    |\n|                                     |\n+-------------------------------------+\n</code></pre> <p>We may wish to calculate a model for star brightness in each of these regions. In this case, we likely do not care about the value of the model outside these regions, e.g. at the point in the image indicated by <code>*</code>. However, our model may still be based on where we are within this larger image.</p> <p>Because of this, it is efficient for us to take this image and cast it into a sparse representation using <code>scipy</code>'s <code>sparse</code> library.</p> <p>Unfortunately <code>sparse</code> does not easily enable us to do this, as it only allows 2D arrays.</p> <p>This small repository implements a way that we can hold the data corresponding to each of the sub-images inside of a sparse array, by \"unwrapping\" the indices for the sub-images and insetting them in the larger, sparse image.</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install with pip using</p> <pre><code>pip install sparse3d --upgrade\n</code></pre> <p>or you can clone this repo and install using</p> <pre><code>cd sparse3d/\npip install poetry --upgrade\npoetry install\n</code></pre>"},{"location":"0-start-here/","title":"What is <code>Sparse3D</code>?","text":"<p><code>Sparse3D</code> is a class designed to work with images made up of small, dense regions. Really, this is designed for astronomy images, but there might be other use cases. </p> <p>Here we'll talk a lot about sparse and dense data. Sparse just means \"mostly containing zeros\", and dense means \"mostly containing non-zero values\".</p>"},{"location":"0-start-here/#what-are-we-trying-to-achieve-in-astronomy","title":"What are we trying to achieve in astronomy?","text":"<p>Astronomy images tend to be large and sparse; they usually do not have a lot of stars in them. In addition, there are usually many, small, dense regions where there are stars. We frequently want to model these images.</p> <p>Let's imagine we have an astronomy image that looks like this; it is a mostly sparse image, with two stars in it. The stars create dense regions (i.e. valued pixels), I've labeled the regions A and B.</p> <pre><code>\n        +-------------------------------------+\n        |                                     |\n        |                                     |\n        |                                     |\n        |   +-----+        +-----+            |\n        |   |     |        |     |            |\n        |   |  A  |        |  B  |            |\n        |   |     |        |     |            |\n        |   +-----+        +-----+            |\n        |                                     |\n        |                                     |\n        |                                     |\n        |                                     |\n        |                                     |\n        |                                     |\n        +-------------------------------------+\n</code></pre> <p>If we wanted a model for this image, we could build a PSF model for the stars, and then evaluate it across every part of the image. This is tractable for small images, and few stars, but quickly becomes expensive. </p> <p>The above image might be easy to model if we cut it into pieces, but what happens when stars overlap</p> <pre><code>        +-------------------------------------+\n        |                                     |\n        |                                     |\n        |                                     |\n        |   +-----+        +-----+            |\n        |   |     |        |     |            |\n        |   |  A  |        |  B  |            |\n        |   |     |        +-----+            |\n        |   +-----+        +-----+            |\n        |                  |  C  |            |\n        |   +-----+        |     |            |\n        |   |     |        +-----+            |\n        |   |  D  |                           |\n        |   |     |                           |\n        |   +-----+                           |\n        |                                     |\n        +-------------------------------------+\n</code></pre> <p>Now to model the image we will have to model the B and C regions simultaneously, because they overlap.</p> <p>If we want to do this we're going to need to evaluate the model for regions A, B, C, D and calculate the best fitting linear sum of these regions. </p> <pre><code>                +-------------------------------------+\n               /|                                     /|\n              / |                                    / |\n             /  +-----+        +-----+              /  |\n            /   |     |        |     |             /   |\n           /    |  A  |        |  B  |            /    |\n          /     |     |        |     |           /     |\n         /      +-----+        +-----+          /      |\n        +-------------------------------------+/       |\n        |                                     |        |\n        |                  +-----+            |        |\n        |                  |     |            |        |\n        |                  |  C  |            |        |\n        |   +-----+        |     |            |        |\n        |   |     |        +-----+            |        |\n        |   |  D  |                           |        |\n        |   |     |                           |       / \n        |   +-----+                           |      /\n        |                                     |     /\n        |                                     |    /\n        |                                     |   /\n        +-------------------------------------+ \n</code></pre> <p>This might look something like the cube above. This is an even sparser dataset than the image, with each layer of the cube containing values only in one of the dense regions. </p> <p>If we dot this cube with a set of weights \\([A_w, B_w, C_w, D_w]\\) we will get an image back, with all the regions multiplied by a value and added.</p> <p>Creating this cube is intractable in astronomy if we have to keep track of all the zeros in memory. We would like to use the <code>sparse</code> library from <code>scipy</code>, but those arrays will not let us hold cubes. This is where <code>Sparse3D</code> comes in. <code>Sparse3D</code> will let you hold and work with this data, so that you can quickly compute your astronomy models.</p>"},{"location":"0-start-here/#simple-example","title":"Simple Example","text":"<p>Below I show an example where we set up a 512 x 512 image, with 500 sources in it. I randomly distribute the sources. </p> <pre><code>from sparse3d import Sparse3D\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimshape = (512, 512)\nnsources = 500\nsource_row, source_col = np.random.uniform(0, 512, size=(nsources, 2)).T\n\n# These are the row and column positions of all the images\nR, C = np.mgrid[:20, :20] - 10\nR, C = R[:, :, None], C[:, :, None]\n</code></pre> <p>To show an example, I am going to create some data which is just ones. I will make a new matrix, and then I will pass in the row and column positions for the data.</p> <pre><code>data = np.ones((20, 20, nsources))\nA = Sparse3D(data=data, row=R + source_row.astype(int), col=C + source_col.astype(int), imshape=imshape)\n</code></pre> <pre><code>A\n</code></pre> <pre><code>&lt;(512, 512, 500) Sparse3D array of type float64&gt;\n</code></pre> <p>Note that even though I passed in data with shape (20, 20, 500), my matrix is now shape (512, 512, 500), the size of the large sparse image.</p> <p>Let's look at the first image in this cube. To turn this into a valued cube we'll dot it with the value 1.</p> <pre><code>plt.imshow(A[:, :, 0].dot(1))\n</code></pre> <pre><code>&lt;matplotlib.image.AxesImage at 0x10ec2b100&gt;\n</code></pre> <p></p> <p>This slice of the cube contains just one dense region, as we expect. That dense region is 20 x 20 pixels. </p> <p>If we dot the entire cube with 500 ones, we will multiply each frame by one, and then sum all the frames.</p> <pre><code>plt.imshow(A.dot(np.ones(500)))\n</code></pre> <pre><code>&lt;matplotlib.image.AxesImage at 0x10eca1400&gt;\n</code></pre> <p></p> <p>This now has all the dense regions summed. You can see they are arranged around the image randomly. If we dot with different weights, we see each of the regions are weighted accordingly</p> <pre><code>plt.imshow(A.dot(np.random.normal(size=500)))\n</code></pre> <pre><code>&lt;matplotlib.image.AxesImage at 0x10f2c07f0&gt;\n</code></pre> <p></p> <p>Now you can now move onto the astronomy demonstration to see how this is useful for astronomy data.</p>"},{"location":"1-astronomy-demo/","title":"Using <code>Sparse3D</code>","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sparse3d import Sparse3D\n\nfrom scipy import sparse\n</code></pre> <p>Let's imagine a scenario where we are trying to model a large astronomy image. Let's set up some image dimensions, and a number of targets to model.</p> <p>We'll need to have some model for the source shape. Let's pick a simple 2D Gaussian for now, with a standard deviation of 2 pixels. </p> <pre><code>imshape = (1024, 1024)\nnsources = 50000\nsource_brightness = 10**np.random.normal(0, 1.5, size=nsources)# * 10\nsource_row, source_col = np.random.uniform(0, 1024, size=(nsources, 2)).T\nsigma = 1\n</code></pre> <pre><code>plt.hist(source_brightness, np.linspace(0, 100, 100));\n</code></pre> <p></p> <p>If we want to model this, we have to</p> <ol> <li>Create a model for each source</li> <li>Add the sources together</li> </ol> <p>This will require that we evaluate the Gaussian function for 50000 sources, and evaluate it out to some distance. If we try to calculate the full model across all the pixels possible we will end up with a very slow calculation. </p> <p>Let's use Sparse3D to calculate it.</p> <p>First let's decide how far out from each source we want to evaulate the model. Given that we're going to use a Gaussian, we'll go out 5 standard deviations from each side.</p> <pre><code>subimage_size = sigma * 5 * 2\n</code></pre> <p>We need the indices in row and column for each sub image around a star. This needs to be in integer, pixel positions. </p> <p>We're obtain the integer row and column position for each source, and then the phase in that pixel.</p> <pre><code>source_row_int, source_row_phase = np.floor(source_row).astype(int), source_row % 1\nsource_col_int, source_col_phase = np.floor(source_col).astype(int), source_col % 1\n</code></pre> <p>Then we can create the grid of pixel offsets</p> <pre><code>R, C = np.mgrid[:subimage_size, :subimage_size] - subimage_size//2\n</code></pre> <pre><code>R\n</code></pre> <pre><code>array([[-5, -5, -5, -5, -5, -5, -5, -5, -5, -5],\n       [-4, -4, -4, -4, -4, -4, -4, -4, -4, -4],\n       [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3],\n       [-2, -2, -2, -2, -2, -2, -2, -2, -2, -2],\n       [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n       [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n       [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n       [ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3],\n       [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4]])\n</code></pre> <pre><code>R.shape\n</code></pre> <pre><code>(10, 10)\n</code></pre> <p>This defines the pixel indices in our sub array. </p> <p>The integer row and column position in 3D for each source is then given as</p> <pre><code>row3d = R[:, :, None] + source_row_int\ncol3d = C[:, :, None] + source_col_int\n</code></pre> <pre><code>row3d.shape\n</code></pre> <pre><code>(10, 10, 50000)\n</code></pre> <p>We can see that the shape of this array is (10, 10, 100000) which is (nrows, ncolumns, nsources).</p> <p>If we look at the first source we get</p> <pre><code>row3d[:, :, 0]\n</code></pre> <pre><code>array([[229, 229, 229, 229, 229, 229, 229, 229, 229, 229],\n       [230, 230, 230, 230, 230, 230, 230, 230, 230, 230],\n       [231, 231, 231, 231, 231, 231, 231, 231, 231, 231],\n       [232, 232, 232, 232, 232, 232, 232, 232, 232, 232],\n       [233, 233, 233, 233, 233, 233, 233, 233, 233, 233],\n       [234, 234, 234, 234, 234, 234, 234, 234, 234, 234],\n       [235, 235, 235, 235, 235, 235, 235, 235, 235, 235],\n       [236, 236, 236, 236, 236, 236, 236, 236, 236, 236],\n       [237, 237, 237, 237, 237, 237, 237, 237, 237, 237],\n       [238, 238, 238, 238, 238, 238, 238, 238, 238, 238]])\n</code></pre> <p>i.e. the row position for the first source.</p> <p>We need to build our model. Our model is given as</p> \\[ f(x, y) = \\frac{1}{2 \\pi \\sigma_x \\sigma_y} \\exp \\left( -\\frac{1}{2} \\left( \\frac{(\\mathbf{X} - \\mathbf{\\mu_x})^2}{\\sigma_x^2} + \\frac{(\\mathbf{Y} - \\mathbf{\\mu_y})^2}{\\sigma_y^2} \\right) \\right) \\] <p>where \\(dx\\) and \\(dy\\) indicate the distance from the source position in x and y.</p> <p>Let's create arrays for both the \\(x\\) and \\(y\\) terms</p> <pre><code>x3d = R[:, :, None] * np.ones(nsources)\ny3d = C[:, :, None] * np.ones(nsources)\n</code></pre> <pre><code>X = Sparse3D(data=x3d, row=row3d, col=col3d, imshape=imshape)\nY = Sparse3D(data=y3d, row=row3d, col=col3d, imshape=imshape)\n</code></pre> <pre><code>X\n</code></pre> <pre><code>&lt;(1024, 1024, 50000) Sparse3D array of type float64&gt;\n</code></pre> <pre><code>mu_x = source_row_phase\nmu_y = source_col_phase\n</code></pre> <p>Here we will define L to be the 2D Gaussian representing the PSF of each source</p> <pre><code>L = 1/(2*np.pi * sigma**2) * np.exp(-0.5*((X - mu_x)**2/sigma**2 + (Y - mu_y)**2/sigma**2))\n</code></pre> <pre><code>L\n</code></pre> <pre><code>&lt;(1024, 1024, 50000) Sparse3D array of type float64&gt;\n</code></pre> <p><code>L</code> is now a matrix containing our 50000 targets. Each target is only valued in a small region, close to the target center. For us to convert this into a flat image containing all the sources at a given brightness, we just use the dot product.</p> <pre><code>model_image = L.dot(source_brightness)\n</code></pre> <p>If we plot this new model image, we see all the sources!</p> <pre><code>fig, ax = plt.subplots(figsize=(6, 6))\nax.imshow(model_image, vmin=0, vmax=10, origin='lower');\nax.set(xlabel='Column', ylabel='Row', title='Model Image')\n</code></pre> <pre><code>[Text(0.5, 0, 'Column'), Text(0, 0.5, 'Row'), Text(0.5, 1.0, 'Model Image')]\n</code></pre> <p></p> <p>Let's try imagining this is real data. We can add some noise, and then use our matrix to fit the data.</p> <pre><code>fake_data = np.random.poisson(model_image) + np.random.normal(0, 3, size=model_image.shape).astype(int)\n</code></pre> <p>I've sampled the image using poisson noise to simulate observing real stars, and I've added in a small Gaussian noise to act as \"read noise\".</p> <p>We now want to fit the brightness of each star. In this contrived case, I have a perfect model for the data (I made the data!), let's extract the flux for these targets. </p> <p>We'll fit this by converting our Sparse3D matrix to a <code>sparse.csr_matrix</code> which will give us a 2D matrix, and then we can do our regular linear algebra.. </p> <pre><code>Lc = L.tocsr()\n</code></pre> <p>Let's look at the difference between these two arrays:</p> <pre><code>L\n</code></pre> <pre><code>&lt;(1024, 1024, 50000) Sparse3D array of type float64&gt;\n</code></pre> <pre><code>Lc\n</code></pre> <pre><code>&lt;1048576x50000 sparse matrix of type '&lt;class 'numpy.float64'&gt;'\n    with 4976958 stored elements in Compressed Sparse Row format&gt;\n</code></pre> <p>Note this new matrix has shape (npixels, nsources). </p> <p>We've converted it so we can use linear algebra functions. We can use simple linear algebra to fit our fake data and find the 50000 sources.</p> <pre><code>%%time\nbest_fit_weights = sparse.linalg.spsolve(Lc.T.dot(Lc), sparse.csc_matrix(Lc.T.dot(fake_data.ravel())).T)\n</code></pre> <pre><code>CPU times: user 1.39 s, sys: 26.2 ms, total: 1.42 s\nWall time: 1.45 s\n</code></pre> <pre><code>len(best_fit_weights)\n</code></pre> <pre><code>50000\n</code></pre> <p>You can see we've fit 50,000 stars in this image in less than 2 seconds. Let's plot the fit against the truth.</p> <pre><code>fig, ax = plt.subplots()\nax.scatter(source_brightness, best_fit_weights, s=1, c='k')\nax.plot([1e-4, 1e6], [1e-4, 1e6], c='r', ls='--')\nax.set(yscale='log', xscale='log', xlabel='Truth', ylabel='Measured');\n</code></pre> <p></p> <p>This looks great! Bright sources have very similar flux to the expected flux, but fainter sources are more noisy as we get towards the read noise limit of the data. </p> <p>Of course, in this contrived case, I know the true model. In reality, we won't actually know the PSF model, or the exact location of the stars. But you can see given real data and an approximate model how this can be recreated. </p>"},{"location":"1-astronomy-demo/#hints-1-efficiency","title":"Hints 1: Efficiency","text":"<p>Keep in mind every operation you do on one of these objects is costing some time to remake the object.</p> <p>For example</p> <pre><code>Sparse3D + 1 + np.ones(10) + 324\n</code></pre> <p>is less efficient than</p> <pre><code>Sparse3D + (1 + np.ones(10) + 324)\n</code></pre> <p>so you can improve efficiency by calculating as much as you can in numpy, then casting into a <code>Sparse3D</code> object</p> <pre><code>dX1 = Sparse3D(-0.5 * (x3d - source_row_phase)**2/sigma**2, row3d, col3d, imshape=imshape)\ndY1 = Sparse3D(-0.5 * (y3d - source_col_phase)**2/sigma**2, row3d, col3d, imshape=imshape)\n</code></pre> <pre><code>l = np.exp(dX1 + dY1) * (1/(2*np.pi * sigma**2))\n</code></pre> <pre><code>plt.figure(figsize=(7, 7))\nplt.imshow(l.dot(source_brightness), vmin=0, vmax=10);\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"roisparse3d/","title":"Documentation for <code>Sparse3D</code>","text":"<p>               Bases: <code>Sparse3D</code></p> <p>Special version of a Sparse3D matrix which only populates and works with data within Regions of Interest.</p> Source code in <code>src/sparse3d/sparse3d.py</code> <pre><code>class ROISparse3D(Sparse3D):\n    \"\"\"Special version of a Sparse3D matrix which only populates and works with data within Regions of Interest.\"\"\"\n\n    def __init__(\n        self,\n        data: np.ndarray,\n        row: np.ndarray,\n        col: np.ndarray,\n        imshape: Tuple[int, int],\n        nROIs: int,\n        ROI_size: Tuple[int, int],\n        ROI_corners: List[Tuple[int, int]],\n        imcorner: Tuple[int, int] = (0, 0),\n    ) -&gt; None:\n        \"\"\"\n        Initialize a Sparse3D instance with 3D dense data, and specify regions of interest that are required by the user.\n\n        This class is designed enable work with small, dense sub images within a larger, sparse image.\n\n        In some applications, we care about \"regions of interest\" within a larger image. Some examples;\n\n            1. Target Pixel Files from NASA Kepler are small regions of interest from a large image.\n            Positions of the TPFs in the larger image dictate the background expected, or the PSF shape expected.\n            Inside each Target Pixel File there might be many stars\n            2. Similarly, NASA Pandora will downlink regions of interest from a larger full frame image. The\n            regions of interet may contain several targets.\n\n        This gives us an updated image below:\n\n        +-------------------------------------------------+\n        |                                                 |\n        |   +-----------+          +-----------+          |\n        |   |  +---+    |          |  +---+    |          |\n        |   |  | A |    |          |  | B |    |          |\n        |   |  +---+    |          |  +---+    |          |\n        |   |  ROI 1    |          |  ROI 2  +---+        |\n        |   +-----------+          +---------| E |        |\n        |                                    +---+        |\n        |                                                 |\n        |                    +-----------+                |\n        |                    |         +---+              |\n        |                    |         | C |              |\n        |   +-----------+    |         +---+              |\n        |   |    +---+  |    |   ROI 3   |                |\n        |   |    | D |  |    +-----------+                |\n        |   |    +---+  |                                 |\n        |   |   ROI 4   |                     +---+       |\n        |   +-----------+                     | F |       |\n        |                                     +---+       |\n        +-------------------------------------------------+\n\n        In this case, we want to understand the images and their relative position within a larger image,\n        but we do not want to calculate any values outside of those regions of interest, and we want\n        the data to be returned to us with the shape of the region of interest. We do not expect the user\n        to provide data outside of the regions of interest. For example, in the above diagram the \"F\"\n        sub image is not close to a region of interest, and so would be superfluous.\n\n        Parameters\n        ----------\n        data : np.ndarray\n            A dense 3D array containing data elements of shape `(nrows, ncols, n sub images)`.\n            The shape of data defines the size and number of dense sub images.\n        row : np.ndarray\n            A 3D array indicating the row indices of non-zero elements, with shape `(nrows, ncols, n sub images)`.\n        col : np.ndarray\n            A 3D array indicating the column indices of non-zero elements, with shape `(nrows, ncols, n sub images)`.\n        imshape : tuple of int\n            A tuple `(row, column)` defining the shape of the larger, sparse image.\n        nROIs: int\n            The number of regions of interest in the larger image\n        ROI_size: Tuple\n            The size the regions of interest in (row, column) pixels. All ROIs must be the same size.\n        ROI_corners: List[Tuple[int, int]]\n            The origin (lower left) corner positon for each of the ROIs. Must have length nROIs.\n        imcorner : tuple of int\n            A tuple `(row, column)` defining the corner of the larger, sparse image. Defaults to (0, 0)\n\n        Raises\n        ------\n        ValueError\n            If `data`, `row`, or `col` are not 3D arrays, or if their third dimensions do not match.\n        ValueError\n            If corners are not passed for all ROIs\n        ValueError\n            If corners are not passed as tuples.\n        \"\"\"\n        self.nROIs = nROIs\n        self.ROI_size = ROI_size\n        self.ROI_corners = ROI_corners\n        # self.imcorner = imcorner\n        self.get_ROI_mask = self._parse_ROIS(nROIs, ROI_size, ROI_corners)\n        super().__init__(\n            data=data, row=row, col=col, imshape=imshape, imcorner=imcorner\n        )\n\n    def _parse_ROIS(self, nROIs: int, ROI_size: tuple, ROI_corners: list):\n        \"\"\"Method checks the ROI inputs are allowable. Returns a function to obtain the boolean mask describing the ROIs\"\"\"\n        if not len(ROI_corners) == nROIs:\n            raise ValueError(\"Must pass corners for all ROIs.\")\n        if not np.all([isinstance(corner, tuple) for corner in ROI_corners]):\n            raise ValueError(\"Pass corners as tuples.\")\n\n        def get_ROI_masks_func(row, column):\n            mask = []\n            for roi in range(nROIs):\n                rmin, cmin = ROI_corners[roi]\n                rmax, cmax = rmin + ROI_size[0], cmin + ROI_size[1]\n                mask.append(\n                    (row &gt;= rmin)\n                    &amp; (row &lt; rmax)\n                    &amp; (column &gt;= cmin)\n                    &amp; (column &lt; cmax)\n                )\n            return np.asarray(mask)\n\n        return get_ROI_masks_func\n\n    def __repr__(self):\n        return f\"&lt;{(*self.imshape, self.nsubimages)} ROISparse3D array of type {self.dtype}, {self.nROIs} Regions of Interest&gt;\"\n\n    def __len__(self):\n        return self.shape[-1]\n\n    # def _get_submask(self, offset=(0, 0)):\n    #     # find where the data is within the array bounds\n    #     kr = ((self.subrow + offset[0]) &lt; self.imshape[0]) &amp; (\n    #         (self.subrow + offset[0]) &gt;= 0\n    #     )\n    #     kc = ((self.subcol + offset[1]) &lt; self.imshape[1]) &amp; (\n    #         (self.subcol + offset[1]) &gt;= 0\n    #     )\n    #     # kroi = self.get_ROI_mask(self.subrow + offset[0], self.subcol + offset[0]).any(\n    #     #     axis=0\n    #     # )\n    #     return kr &amp; kc &amp; self._kz  # &amp; kroi\n\n    def _new_s3d(self, new_data, new_row, new_col):\n        \"\"\"Convenience function to return a new version of this class\"\"\"\n        return self.__class__(\n            data=new_data,\n            row=new_row + self.imcorner[0],\n            col=new_col + self.imcorner[1],\n            imshape=self.imshape,\n            imcorner=self.imcorner,\n            nROIs=self.nROIs,\n            ROI_size=self.ROI_size,\n            ROI_corners=self.ROI_corners,\n        )\n\n    def dot(self, other):\n        \"\"\"\n        Compute the dot product with another array.\n\n        This method calculates the dot product of this ROISparse3D instance with a 1D or 2D `numpy.ndarray` or sparse array\n        If `other` is a 1D array, it will be treated as a column vector for the dot product. The resulting product is reshaped\n        to match the original image shape with an added dimension for multi-dimensional results if `other` is 2D.\n\n        Parameters\n        ----------\n        other : np.ndarray, sparse.csr_matrix\n            A 1D or 2D array to perform the dot product with. The first dimension must be the number of sub images\n            in the Sparse3D instance (i.e should match `self.nsubimages`). If the vector is 1D, it will be recast to have shape\n            (n sub images, 1).\n\n        Returns\n        -------\n        np.ndarray\n            The resulting array from the dot product, reshaped to match the image dimensions `(self.nROIs, n, *self.ROI_size)`\n            where n is the length of the second dimension of `other`.\n            This will always be a 4D dataset.\n        \"\"\"\n        ndim = other.ndim\n        if isinstance(other, np.ndarray):\n            other = sparse.csr_matrix(other).T\n        if not sparse.issparse(other):\n            raise ValueError(\"Must pass a `sparse` array to dot.\")\n        if not other.shape[0] == self.nsubimages:\n            if other.shape[1] == self.nsubimages:\n                other = other.T\n            else:\n                raise ValueError(\n                    f\"Must pass {(self.nsubimages, 1)} shape object.\"\n                )\n        sparse_array = super().tocsr().dot(other)\n\n        R, C = np.meshgrid(\n            np.arange(0, self.ROI_size[0]),\n            np.arange(0, self.ROI_size[1]),\n            indexing=\"ij\",\n        )\n        array = np.zeros((self.nROIs, other.shape[1], *self.ROI_size))\n        for rdx, c in enumerate(self.ROI_corners):\n            idx = (R.ravel() + c[0] - self.imcorner[0]) * self.imshape[1] + (\n                C.ravel() + c[1] - self.imcorner[1]\n            )\n            k = (idx &gt;= 0) &amp; (idx &lt; self.shape[0])\n            array[rdx, :, k.reshape(self.ROI_size)] = sparse_array[\n                idx[k]\n            ].toarray()  # ).reshape(self.ROI_size))\n        if ndim == 1:\n            return array[:, 0, :, :]\n        return array\n\n    def to_Sparse3D(self):\n        return Sparse3D(\n            data=self.subdata,\n            row=self.subrow,\n            col=self.subcol,\n            imshape=self.imshape,\n            imcorner=self.imcorner,\n        )\n</code></pre>"},{"location":"roisparse3d/#sparse3d.ROISparse3D.dot","title":"<code>dot(other)</code>","text":"<p>Compute the dot product with another array.</p> <p>This method calculates the dot product of this ROISparse3D instance with a 1D or 2D <code>numpy.ndarray</code> or sparse array If <code>other</code> is a 1D array, it will be treated as a column vector for the dot product. The resulting product is reshaped to match the original image shape with an added dimension for multi-dimensional results if <code>other</code> is 2D.</p>"},{"location":"roisparse3d/#sparse3d.ROISparse3D.dot--parameters","title":"Parameters","text":"<p>other : np.ndarray, sparse.csr_matrix     A 1D or 2D array to perform the dot product with. The first dimension must be the number of sub images     in the Sparse3D instance (i.e should match <code>self.nsubimages</code>). If the vector is 1D, it will be recast to have shape     (n sub images, 1).</p>"},{"location":"roisparse3d/#sparse3d.ROISparse3D.dot--returns","title":"Returns","text":"<p>np.ndarray     The resulting array from the dot product, reshaped to match the image dimensions <code>(self.nROIs, n, *self.ROI_size)</code>     where n is the length of the second dimension of <code>other</code>.     This will always be a 4D dataset.</p> Source code in <code>src/sparse3d/sparse3d.py</code> <pre><code>def dot(self, other):\n    \"\"\"\n    Compute the dot product with another array.\n\n    This method calculates the dot product of this ROISparse3D instance with a 1D or 2D `numpy.ndarray` or sparse array\n    If `other` is a 1D array, it will be treated as a column vector for the dot product. The resulting product is reshaped\n    to match the original image shape with an added dimension for multi-dimensional results if `other` is 2D.\n\n    Parameters\n    ----------\n    other : np.ndarray, sparse.csr_matrix\n        A 1D or 2D array to perform the dot product with. The first dimension must be the number of sub images\n        in the Sparse3D instance (i.e should match `self.nsubimages`). If the vector is 1D, it will be recast to have shape\n        (n sub images, 1).\n\n    Returns\n    -------\n    np.ndarray\n        The resulting array from the dot product, reshaped to match the image dimensions `(self.nROIs, n, *self.ROI_size)`\n        where n is the length of the second dimension of `other`.\n        This will always be a 4D dataset.\n    \"\"\"\n    ndim = other.ndim\n    if isinstance(other, np.ndarray):\n        other = sparse.csr_matrix(other).T\n    if not sparse.issparse(other):\n        raise ValueError(\"Must pass a `sparse` array to dot.\")\n    if not other.shape[0] == self.nsubimages:\n        if other.shape[1] == self.nsubimages:\n            other = other.T\n        else:\n            raise ValueError(\n                f\"Must pass {(self.nsubimages, 1)} shape object.\"\n            )\n    sparse_array = super().tocsr().dot(other)\n\n    R, C = np.meshgrid(\n        np.arange(0, self.ROI_size[0]),\n        np.arange(0, self.ROI_size[1]),\n        indexing=\"ij\",\n    )\n    array = np.zeros((self.nROIs, other.shape[1], *self.ROI_size))\n    for rdx, c in enumerate(self.ROI_corners):\n        idx = (R.ravel() + c[0] - self.imcorner[0]) * self.imshape[1] + (\n            C.ravel() + c[1] - self.imcorner[1]\n        )\n        k = (idx &gt;= 0) &amp; (idx &lt; self.shape[0])\n        array[rdx, :, k.reshape(self.ROI_size)] = sparse_array[\n            idx[k]\n        ].toarray()  # ).reshape(self.ROI_size))\n    if ndim == 1:\n        return array[:, 0, :, :]\n    return array\n</code></pre>"},{"location":"sparse3d/","title":"Documentation for <code>Sparse3D</code>","text":"<p>               Bases: <code>Sparse3DMathMixin</code>, <code>coo_matrix</code></p> <p>Special class for working with stacks of sparse 3D images</p> Source code in <code>src/sparse3d/sparse3d.py</code> <pre><code>class Sparse3D(Sparse3DMathMixin, sparse.coo_matrix):\n    \"\"\"Special class for working with stacks of sparse 3D images\"\"\"\n\n    # def __init__(self, data, row, col, imshape):\n    def __init__(\n        self,\n        data: np.ndarray,\n        row: np.ndarray,\n        col: np.ndarray,\n        imshape: Tuple[int, int],\n        imcorner: Tuple[int, int] = (0, 0),\n    ) -&gt; None:\n        \"\"\"\n        Initialize a Sparse3D instance with 3D dense data.\n\n        This class is designed enable work with small, dense sub images within a larger, sparse image.\n\n        This class takes in 3D dense data, and the row and column positions within the larger image of each of the data points.\n        The data, row and column should have shape (nrows, ncols, n sub images).\n\n        For example, below represents 4 dense image sub images (A, B, C, D) within a larger, sparse image. This would be input using\n        with data of shape (nrows, ncols, 4) corresponding to the size of the sub images in row and colum, and the number of sub images.\n        The size of the larger image is specified with `imshape`. All sub images must have the same size.\n\n        +-------------------------------------+\n        |                                     |\n        |   +-----+        +-----+            |\n        |   |     |        |     |            |\n        |   |  A  |        |  B  |            |\n        |   |     |        |     |            |\n        |   +-----+        +-----+            |\n        |                                     |\n        |                  +-----+            |\n        |                  |     |            |\n        |   +-----+        |  C  |            |\n        |   |     |        |     |            |\n        |   |  D  |        +-----+            |\n        |   |     |                           |\n        |   +-----+                           |\n        |                                     |\n        +-------------------------------------+\n\n\n        Parameters\n        ----------\n        data : np.ndarray\n            A dense 3D array containing data elements of shape `(nrows, ncols, n sub images)`.\n            The shape of data defines the size and number of dense sub images.\n        row : np.ndarray\n            A 3D array indicating the row indices of non-zero elements, with shape `(nrows, ncols, n sub images)`.\n        col : np.ndarray\n            A 3D array indicating the column indices of non-zero elements, with shape `(nrows, ncols, n sub images)`.\n        imshape : tuple of int\n            A tuple `(row, column)` defining the shape of the larger, sparse image.\n        imcorner : tuple of int\n            A tuple `(row, column)` defining the corner of the larger, sparse image. Defaults to (0, 0)\n\n        Raises\n        ------\n        ValueError\n            If `data`, `row`, or `col` are not 3D arrays, or if their third dimensions do not match.\n\n        \"\"\"\n        if not np.all([row.ndim == 3, col.ndim == 3, data.ndim == 3]):\n            raise ValueError(\"Pass a 3D array (nrow, ncol, nsubimages)\")\n        self.nsubimages = data.shape[-1]\n        self.imshape = imshape\n        self.imcorner = imcorner\n\n        if not np.all(\n            [\n                row.shape[-1] == self.nsubimages,\n                col.shape[-1] == self.nsubimages,\n            ]\n        ):\n            raise ValueError(\"Must have the same 3rd dimension (nsubimages).\")\n        self.subrow = row.astype(int) - self.imcorner[0]\n        self.subcol = col.astype(int) - self.imcorner[1]\n        self.subdepth = (\n            np.arange(row.shape[-1], dtype=int)[None, None, :]\n            * np.ones(row.shape[:2], dtype=int)[:, :, None]\n        )\n        # The data for the sub images. We can not overwrite `self.data`, which is property of the COO matrix.\n        self.subdata = data\n        # We use this mask repeatedly so we calculate once on initialization.\n        self._kz = self.subdata != 0\n\n        self.subshape = row.shape\n        self.cooshape = (np.prod([*self.imshape[:2]]), self.nsubimages)\n        self.coord = (0, 0)\n        super().__init__(self.cooshape)\n\n        # In order to simulate the data being three dimensional, we unwrap the 3D indicies into 2D\n        # (row, column) -&gt; row position within the sparse array.\n        index0 = (np.vstack(self.subrow)) * self.imshape[1] + (\n            np.vstack(self.subcol)\n        )\n        # (nsubimage) -&gt; column position in the sparse array.\n        index1 = np.vstack(self.subdepth).ravel()\n\n        # We will reuse this when we reset the data so we store it once.\n        self._index_no_offset = np.vstack([index0.ravel(), index1.ravel()])\n        # This mask represents where the input data is within bounds of self.imshape.\n        self._submask_no_offset = np.vstack(\n            self._get_submask(offset=(0, 0))\n        ).ravel()\n\n        # We use these to calculate translations, so we calculate them once.\n        self._subrow_v = deepcopy(np.vstack(self.subrow).ravel())\n        self._subcol_v = deepcopy(np.vstack(self.subcol).ravel())\n        self._subdata_v = deepcopy(np.vstack(deepcopy(self.subdata)).ravel())\n\n        self._index1 = np.vstack(self.subdepth).ravel()\n        self._set_data()\n\n    def multiply(self, other):\n        \"\"\"Returns a matrix with the same sparsity structure as self,\n        but with different data. By default the index arrays are copied.\n        \"\"\"\n        return self._new_s3d(\n            new_data=self.subdata * other,\n            new_row=self.subrow,\n            new_col=self.subcol,\n        )\n\n    def __repr__(self):\n        return f\"&lt;{(*self.imshape, self.nsubimages)} Sparse3D array of type {self.dtype}&gt;\"\n\n    def __len__(self):\n        return self.shape[-1]\n\n    def tocoo(self):\n        \"\"\"Returns a COO matrix built from this Sparse3D instance.\"\"\"\n        return sparse.coo_matrix(\n            (self.data, (self.row, self.col)), shape=self.cooshape\n        )\n\n    def copy(self):\n        \"\"\"Returns a deepcopy of self.\"\"\"\n        return deepcopy(self)\n\n    def _new_s3d(self, new_data, new_row, new_col):\n        \"\"\"Convenience function to return a new version of this class\"\"\"\n        return self.__class__(\n            data=new_data,\n            row=new_row + self.imcorner[0],\n            col=new_col + self.imcorner[1],\n            imshape=self.imshape,\n            imcorner=self.imcorner,\n        )\n\n    def __getitem__(self, index):\n        \"\"\"\n        Handle indexing for Sparse3D. Only slices that are full-length for the\n        first two dimensions and slicing on the last dimension are allowed.\n\n        Parameters\n        ----------\n        index : tuple of slices\n            A tuple representing the slicing operation (e.g., [:, :, 0] or [:, :, 1:3]).\n\n        Returns\n        -------\n        Sparse3D\n            A new Sparse3D instance containing the sliced data.\n\n        Raises\n        ------\n        IndexError\n            If the slicing does not span the full length of the first two dimensions or if indexing\n            is attempted on the first two dimensions.\n        \"\"\"\n        # Check if the index is a tuple and has three elements (for 3D slicing)\n        if not isinstance(index, tuple) or len(index) != 3:\n            raise IndexError(\n                \"Indexing must be for three dimensions (e.g., [:, :, 0]).\"\n            )\n\n        # Ensure the first two indices are full slices\n        if index[0] != slice(None) or index[1] != slice(None):\n            raise IndexError(\n                \"Only full slices (:) are allowed for the first two dimensions.\"\n            )\n\n        # Handle the third index (slicing along the last dimension)\n        last_index = index[2]\n\n        # Extract the relevant slice from the data\n        if isinstance(last_index, int):\n            # Return a 2D slice with only the specified last index\n            new_data = self.subdata[:, :, last_index : last_index + 1]\n            new_row = self.subrow[:, :, last_index : last_index + 1]\n            new_col = self.subcol[:, :, last_index : last_index + 1]\n        elif isinstance(last_index, slice):\n            # Return a 3D slice with the range specified by the slice\n            new_data = self.subdata[:, :, last_index]\n            new_row = self.subrow[:, :, last_index]\n            new_col = self.subcol[:, :, last_index]\n        else:\n            raise IndexError(\"The last index must be an integer or a slice.\")\n\n        # Create a new Sparse3D instance with the sliced data\n        return self._new_s3d(\n            new_data=new_data, new_row=new_row, new_col=new_col\n        )\n\n    def dot(self, other: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Compute the dot product with another array.\n\n        This method calculates the dot product of this Sparse3D instance with a 1D or 2D `numpy.ndarray`. If `other`\n        is a 1D array, it will be treated as a column vector for the dot product. The resulting product is reshaped\n        to match the original image shape with an added dimension for multi-dimensional results if `other` is 2D.\n\n        Parameters\n        ----------\n        other : np.ndarray\n            A 1D or 2D array to perform the dot product with. The first dimension must be the number of sub images\n            in the Sparse3D instance (i.e should match `self.nsubimages`). If the vector is 1D, it will be recast to have shape\n            (n sub images, 1).\n\n        Returns\n        -------\n        np.ndarray\n            The resulting array from the dot product, reshaped to match the image dimensions `(n, *self.image_shape)`\n            where n is the length of the second dimension of `other`.\n            This will always be a 3D dataset.\n\n        Raises\n        ------\n        NotImplementedError\n            If `other` is not a `numpy.ndarray`.\n        ValueError\n            If the shape of `other` does not match the required dimensions for the dot product.\n        \"\"\"\n        if isinstance(other, (int, float, list)):\n            other = np.atleast_1d(other)\n        if not isinstance(other, np.ndarray):\n            raise NotImplementedError(\n                f\"dot products with type {type(other)} are not implemented.\"\n            )\n        if other.ndim == 1:\n            result = super().dot(other).reshape(self.imshape)\n        else:\n            nt = other.shape[1]\n            result = (\n                super()\n                .dot(other)\n                .reshape((*self.imshape, nt))\n                .transpose([2, 0, 1])\n            )\n        if hasattr(other, \"unit\"):\n            return result * other.unit\n        return result\n\n    def _index(self, offset=(0, 0)):\n        \"\"\"\n        Function gets the positions within the COO matrix (2D) of the input data (3D)\n        If an offset is provided as a (row, column) tuple, this will also translate the\n        input data by that amount.\n\n        Parameters\n        ----------\n        offset: Tuple\n            (row, column) tuple representing the offset to the row and column of each sub image.\n\n        Returns\n        -------\n        index0 : np.ndarray\n            An index with length self.imshape[0] * self.imshape[1] that describes where each\n            element of the data should be placed in the COO matrix in the first index\n        index1: np.ndarray\n            An index with length self.nsubimages that describes where each\n            element of the data should be placed in the COO matrix in the second index\n        \"\"\"\n        if offset == (0, 0):\n            return self._index_no_offset\n        index0 = (self._subrow_v + offset[0]) * self.imshape[1] + (\n            self._subcol_v + offset[1]\n        )\n        return index0, self._index1\n\n    def _get_submask(self, offset=(0, 0)):\n        \"\"\"\n        Hidden method to find where the data is within the array bounds. This mask can be used to ensure only\n        data within the bounds of `self.imshape` is input to the sparse array when e.g. translated.\n\n        Parameters\n        ----------\n        offset: Tuple\n            (row, column) tuple representing the offset to the row and column of each sub image.\n\n        Returns\n        -------\n        mask : np.ndarray\n            A boolean mask with the same shape as input data, representing data points that are\n            within bounds of self.imshape.\n        \"\"\"\n        kr = ((self.subrow + offset[0]) &lt; self.imshape[0]) &amp; (\n            (self.subrow + offset[0]) &gt;= 0\n        )\n        kc = ((self.subcol + offset[1]) &lt; self.imshape[1]) &amp; (\n            (self.subcol + offset[1]) &gt;= 0\n        )\n        return kr &amp; kc &amp; self._kz\n\n    def _set_data(self, offset=(0, 0)):\n        \"\"\"\n        Hidden method to set the values into the correct position in the matrix.\n\n        If (0, 0) is passed, this will reset the translation of the data.\n        If any other tuple is passed, the row and column indexes of the input data will be\n        translated by that much.\n\n        This is an inplace operation.\n\n        Parameters\n        ----------\n        offset: Tuple\n            (row, column) tuple representing the offset to the row and column of each sub image.\n        \"\"\"\n        if offset == (0, 0):\n            index0, index1 = self._index((0, 0))\n            self.row, self.col = (\n                index0[self._submask_no_offset],\n                index1[self._submask_no_offset],\n            )\n            self.data = self._subdata_v[self._submask_no_offset]\n        else:\n            # find where the data is within the array bounds\n            k = self._get_submask(offset=offset)\n            k = np.vstack(k).ravel()\n            new_row, new_col = self._index(offset=offset)\n            self.row, self.col = new_row[k], new_col[k]\n            self.data = self._subdata_v[k]\n        self.coord = offset\n\n    def translate(self, offset: Tuple):\n        \"\"\"\n        Translate the data in the array by `offset` in integer pixel positions.\n\n        Position is a (row, column) tuple. If the user passes a position (1, 1) row and column indices of\n        the data will be shifted by 1 pixel in the sparse image.\n\n        This is an in place operation, and will move the data from the input positions. i.e. this translation does not stack.\n\n        Parameters\n        ----------\n        offset: Tuple\n            (row, column) tuple representing the offset to the row and column of each sub image.\n        \"\"\"\n        self.reset()\n        # If translating to (0, 0), do nothing\n        if offset == (0, 0):\n            return\n        self.clear()\n        self._set_data(offset=offset)\n        return\n\n    def reset(self):\n        \"\"\"Reset any translation back to the original data\"\"\"\n        self._set_data(offset=(0, 0))\n        self.coord = (0, 0)\n        return\n\n    def clear(self):\n        \"\"\"Clear data in the array. This function will remove all data in the array.\"\"\"\n        self.data = np.asarray([])\n        self.row = np.asarray([])\n        self.col = np.asarray([])\n        self.coord = (0, 0)\n        self.eliminate_zeros()\n        return\n\n    def to_ROISparse3D(\n        self,\n        nROIs: int,\n        ROI_size: Tuple[int, int],\n        ROI_corners: List[Tuple[int, int]],\n    ) -&gt; \"ROISparse3D\":\n        return ROISparse3D(\n            data=self.subdata,\n            row=self.subrow,\n            col=self.subcol,\n            nROIs=nROIs,\n            ROI_size=ROI_size,\n            ROI_corners=ROI_corners,\n            imshape=self.imshape,\n        )\n</code></pre>"},{"location":"sparse3d/#sparse3d.Sparse3D.clear","title":"<code>clear()</code>","text":"<p>Clear data in the array. This function will remove all data in the array.</p> Source code in <code>src/sparse3d/sparse3d.py</code> <pre><code>def clear(self):\n    \"\"\"Clear data in the array. This function will remove all data in the array.\"\"\"\n    self.data = np.asarray([])\n    self.row = np.asarray([])\n    self.col = np.asarray([])\n    self.coord = (0, 0)\n    self.eliminate_zeros()\n    return\n</code></pre>"},{"location":"sparse3d/#sparse3d.Sparse3D.copy","title":"<code>copy()</code>","text":"<p>Returns a deepcopy of self.</p> Source code in <code>src/sparse3d/sparse3d.py</code> <pre><code>def copy(self):\n    \"\"\"Returns a deepcopy of self.\"\"\"\n    return deepcopy(self)\n</code></pre>"},{"location":"sparse3d/#sparse3d.Sparse3D.dot","title":"<code>dot(other)</code>","text":"<p>Compute the dot product with another array.</p> <p>This method calculates the dot product of this Sparse3D instance with a 1D or 2D <code>numpy.ndarray</code>. If <code>other</code> is a 1D array, it will be treated as a column vector for the dot product. The resulting product is reshaped to match the original image shape with an added dimension for multi-dimensional results if <code>other</code> is 2D.</p>"},{"location":"sparse3d/#sparse3d.Sparse3D.dot--parameters","title":"Parameters","text":"<p>other : np.ndarray     A 1D or 2D array to perform the dot product with. The first dimension must be the number of sub images     in the Sparse3D instance (i.e should match <code>self.nsubimages</code>). If the vector is 1D, it will be recast to have shape     (n sub images, 1).</p>"},{"location":"sparse3d/#sparse3d.Sparse3D.dot--returns","title":"Returns","text":"<p>np.ndarray     The resulting array from the dot product, reshaped to match the image dimensions <code>(n, *self.image_shape)</code>     where n is the length of the second dimension of <code>other</code>.     This will always be a 3D dataset.</p>"},{"location":"sparse3d/#sparse3d.Sparse3D.dot--raises","title":"Raises","text":"<p>NotImplementedError     If <code>other</code> is not a <code>numpy.ndarray</code>. ValueError     If the shape of <code>other</code> does not match the required dimensions for the dot product.</p> Source code in <code>src/sparse3d/sparse3d.py</code> <pre><code>def dot(self, other: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Compute the dot product with another array.\n\n    This method calculates the dot product of this Sparse3D instance with a 1D or 2D `numpy.ndarray`. If `other`\n    is a 1D array, it will be treated as a column vector for the dot product. The resulting product is reshaped\n    to match the original image shape with an added dimension for multi-dimensional results if `other` is 2D.\n\n    Parameters\n    ----------\n    other : np.ndarray\n        A 1D or 2D array to perform the dot product with. The first dimension must be the number of sub images\n        in the Sparse3D instance (i.e should match `self.nsubimages`). If the vector is 1D, it will be recast to have shape\n        (n sub images, 1).\n\n    Returns\n    -------\n    np.ndarray\n        The resulting array from the dot product, reshaped to match the image dimensions `(n, *self.image_shape)`\n        where n is the length of the second dimension of `other`.\n        This will always be a 3D dataset.\n\n    Raises\n    ------\n    NotImplementedError\n        If `other` is not a `numpy.ndarray`.\n    ValueError\n        If the shape of `other` does not match the required dimensions for the dot product.\n    \"\"\"\n    if isinstance(other, (int, float, list)):\n        other = np.atleast_1d(other)\n    if not isinstance(other, np.ndarray):\n        raise NotImplementedError(\n            f\"dot products with type {type(other)} are not implemented.\"\n        )\n    if other.ndim == 1:\n        result = super().dot(other).reshape(self.imshape)\n    else:\n        nt = other.shape[1]\n        result = (\n            super()\n            .dot(other)\n            .reshape((*self.imshape, nt))\n            .transpose([2, 0, 1])\n        )\n    if hasattr(other, \"unit\"):\n        return result * other.unit\n    return result\n</code></pre>"},{"location":"sparse3d/#sparse3d.Sparse3D.multiply","title":"<code>multiply(other)</code>","text":"<p>Returns a matrix with the same sparsity structure as self, but with different data. By default the index arrays are copied.</p> Source code in <code>src/sparse3d/sparse3d.py</code> <pre><code>def multiply(self, other):\n    \"\"\"Returns a matrix with the same sparsity structure as self,\n    but with different data. By default the index arrays are copied.\n    \"\"\"\n    return self._new_s3d(\n        new_data=self.subdata * other,\n        new_row=self.subrow,\n        new_col=self.subcol,\n    )\n</code></pre>"},{"location":"sparse3d/#sparse3d.Sparse3D.reset","title":"<code>reset()</code>","text":"<p>Reset any translation back to the original data</p> Source code in <code>src/sparse3d/sparse3d.py</code> <pre><code>def reset(self):\n    \"\"\"Reset any translation back to the original data\"\"\"\n    self._set_data(offset=(0, 0))\n    self.coord = (0, 0)\n    return\n</code></pre>"},{"location":"sparse3d/#sparse3d.Sparse3D.tocoo","title":"<code>tocoo()</code>","text":"<p>Returns a COO matrix built from this Sparse3D instance.</p> Source code in <code>src/sparse3d/sparse3d.py</code> <pre><code>def tocoo(self):\n    \"\"\"Returns a COO matrix built from this Sparse3D instance.\"\"\"\n    return sparse.coo_matrix(\n        (self.data, (self.row, self.col)), shape=self.cooshape\n    )\n</code></pre>"},{"location":"sparse3d/#sparse3d.Sparse3D.translate","title":"<code>translate(offset)</code>","text":"<p>Translate the data in the array by <code>offset</code> in integer pixel positions.</p> <p>Position is a (row, column) tuple. If the user passes a position (1, 1) row and column indices of the data will be shifted by 1 pixel in the sparse image.</p> <p>This is an in place operation, and will move the data from the input positions. i.e. this translation does not stack.</p>"},{"location":"sparse3d/#sparse3d.Sparse3D.translate--parameters","title":"Parameters","text":"<p>offset: Tuple     (row, column) tuple representing the offset to the row and column of each sub image.</p> Source code in <code>src/sparse3d/sparse3d.py</code> <pre><code>def translate(self, offset: Tuple):\n    \"\"\"\n    Translate the data in the array by `offset` in integer pixel positions.\n\n    Position is a (row, column) tuple. If the user passes a position (1, 1) row and column indices of\n    the data will be shifted by 1 pixel in the sparse image.\n\n    This is an in place operation, and will move the data from the input positions. i.e. this translation does not stack.\n\n    Parameters\n    ----------\n    offset: Tuple\n        (row, column) tuple representing the offset to the row and column of each sub image.\n    \"\"\"\n    self.reset()\n    # If translating to (0, 0), do nothing\n    if offset == (0, 0):\n        return\n    self.clear()\n    self._set_data(offset=offset)\n    return\n</code></pre>"}]}